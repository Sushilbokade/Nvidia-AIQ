{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJpvTn+pKitt2NhBRG/JHf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sushilbokade/Nvidia-AIQ/blob/main/Nvidia_AIQ_profiling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "97edcd4f",
        "outputId": "c10b0322-43e3-4bc1-abf7-52eece946341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Distribution not found at: file:///content/examples/getting_started/simple_web_query\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -e examples/getting_started/simple_web_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "076e9861",
        "outputId": "5320640e-abf4-42b4-e88e-290510b3af56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[37m⠋\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mResolving dependencies...                                                     \u001b[0m\r\u001b[2K\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Distribution not found at: file:///content/examples/evaluation_and_profiling/simple_web_query_eval\n"
          ]
        }
      ],
      "source": [
        "!uv pip install -e examples/evaluation_and_profiling/simple_web_query_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "592780fe"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"NVIDIA_API_KEY\" not in os.environ:\n",
        "    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
        "    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d6f48e6",
        "outputId": "c34b7f5c-a8c8-4a60-a961-c0ab91bf8b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-31 12:25:45,036 - aiq.runtime.loader - WARNING - Loading module 'aiq_automated_description_generation.register' from entry point 'aiq_automated_description_generation' took a long time (355.381966 ms). Ensure all imports are inside your registered functions.\n",
            "2025-07-31 12:25:45,060 - aiq.data_models.discovery_metadata - WARNING - Package metadata not found for simple_auth\n",
            "2025-07-31 12:25:45,435 - aiq.cli.commands.start - INFO - Starting AIQ Toolkit from config file: 'examples/getting_started/simple_web_query/configs/config.yml'\n",
            "2025-07-31 12:25:45,437 - aiq.cli.commands.start - WARNING - The front end type in the config file (fastapi) does not match the command name (console). Overwriting the config file front end.\n",
            "2025-07-31 12:25:45,655 - aiq.profiler.utils - WARNING - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function webquery_tool by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
            "2025-07-31 12:25:45,686 - langchain_community.utils.user_agent - WARNING - USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "2025-07-31 12:25:45,702 - aiq_simple_web_query.register - INFO - Generating docs for the webpage: https://docs.smith.langchain.com\n",
            "Fetching pages: 100%|#############################| 1/1 [00:00<00:00,  8.97it/s]\n",
            "2025-07-31 12:25:47,108 - faiss.loader - INFO - Loading faiss.\n",
            "2025-07-31 12:25:47,578 - faiss.loader - INFO - Successfully loaded faiss.\n",
            "\n",
            "Configuration Summary:\n",
            "--------------------\n",
            "Workflow Type: react_agent\n",
            "Number of Functions: 2\n",
            "Number of LLMs: 1\n",
            "Number of Embedders: 1\n",
            "Number of Memory: 0\n",
            "Number of Object Stores: 0\n",
            "Number of Retrievers: 0\n",
            "Number of ITS Strategies: 0\n",
            "Number of Authentication Providers: 0\n",
            "\n",
            "2025-07-31 12:25:49,507 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: What is LangSmith?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: To answer this question, I need to find information about LangSmith.\n",
            "\n",
            "Action: webpage_query\n",
            "Action Input: {\"query\": \"LangSmith\"}\n",
            "\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:25:49,995 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {'query': 'LangSmith'}\n",
            "\u001b[36mTool's response: \n",
            "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
            "\n",
            "LangSmith is a platform for building production-grade LLM applications.\n",
            "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
            "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
            "\n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "\n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view ...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:25:49,995 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {\"query\": \"LangSmith\"}\n",
            "\u001b[36mTool's response: \n",
            "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
            "\n",
            "LangSmith is a platform for building production-grade LLM applications.\n",
            "It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\n",
            "ObservabilityAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.EvalsEvaluate your application over production traffic — score application performance and get human feedback on your data.Prompt EngineeringIterate on prompts, with automatic version control and collaboration features.\n",
            "\n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "\n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view ...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:25:51,287 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: What is LangSmith?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: I now know the final answer\n",
            "\n",
            "Final Answer: LangSmith is a platform for building production-grade LLM (Large Language Model) applications, allowing users to monitor and evaluate their applications, and providing features such as observability, evaluation, and prompt engineering. It is framework-agnostic and can be used with or without LangChain's open source frameworks.\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:25:51,290 - aiq.front_ends.console.console_front_end_plugin - INFO - \n",
            "--------------------------------------------------\n",
            "\u001b[32mWorkflow Result:\n",
            "[\"LangSmith is a platform for building production-grade LLM (Large Language Model) applications, allowing users to monitor and evaluate their applications, and providing features such as observability, evaluation, and prompt engineering. It is framework-agnostic and can be used with or without LangChain's open source frameworks.\"]\u001b[39m\n",
            "--------------------------------------------------\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ],
      "source": [
        "! aiq run --config_file examples/getting_started/simple_web_query/configs/config.yml --input \"What is LangSmith?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef559862",
        "outputId": "bf369741-f52c-4baa-8004-74f40c1ff068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-07-31 12:26:27,150 - aiq.eval.evaluate - INFO - Starting evaluation run with config file: examples/evaluation_and_profiling/simple_web_query_eval/configs/eval_config.yml\n",
            "2025-07-31 12:26:27,697 - aiq.runtime.loader - WARNING - Loading module 'aiq_automated_description_generation.register' from entry point 'aiq_automated_description_generation' took a long time (282.423019 ms). Ensure all imports are inside your registered functions.\n",
            "2025-07-31 12:26:27,719 - aiq.data_models.discovery_metadata - WARNING - Package metadata not found for simple_auth\n",
            "2025-07-31 12:26:28,184 - aiq.profiler.utils - WARNING - Discovered frameworks: {<LLMFrameworkEnum.LANGCHAIN: 'langchain'>} in function webquery_tool by inspecting source. It is recommended and more reliable to instead add the used LLMFrameworkEnum types in the framework_wrappers argument when calling @register_function.\n",
            "2025-07-31 12:26:28,198 - langchain_community.utils.user_agent - WARNING - USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "2025-07-31 12:26:28,213 - aiq_simple_web_query.register - INFO - Generating docs for the webpage: https://docs.smith.langchain.com\n",
            "Fetching pages: 100%|#############################| 1/1 [00:00<00:00,  8.56it/s]\n",
            "2025-07-31 12:26:29,017 - faiss.loader - INFO - Loading faiss.\n",
            "2025-07-31 12:26:29,059 - faiss.loader - INFO - Successfully loaded faiss.\n",
            "Running workflow:   0%|                                   | 0/5 [00:00<?, ?it/s]2025-07-31 12:26:35,532 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: What is the purpose of LangSmith's evaluation features?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: To answer this question, I need to find information about LangSmith's evaluation features.\n",
            "\n",
            "Action: webpage_query\n",
            "Action Input: {\"query\": \"LangSmith evaluation features\"}\n",
            "\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,553 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: How does LangSmith support prompt engineering?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: To answer this question, I need to find information about LangSmith's support for prompt engineering.\n",
            "\n",
            "Action: webpage_query\n",
            "Action Input: {\"query\": \"LangSmith prompt engineering\"}\n",
            "\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,584 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: Is LangSmith framework-specific or can it be used with any LLM application?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: To answer this question, I need to find information about LangSmith and its compatibility with different LLM applications.\n",
            "Action: webpage_query\n",
            "Action Input: {\"query\": \"LangSmith framework-specific\"}\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,667 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: What are the main features of LangSmith?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: To answer this question, I need to find information about LangSmith. I will use the webpage_query tool to search for information about LangSmith.\n",
            "\n",
            "Action: webpage_query\n",
            "Action Input: {\"query\": \"LangSmith features\"}\n",
            "\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,705 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: How does LangSmith help with LLM application observability?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: To answer this question, I need to find information about LangSmith and its features related to LLM application observability.\n",
            "\n",
            "Action: webpage_query\n",
            "Action Input: {\"query\": \"LangSmith LLM application observability\"}\n",
            "\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,916 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {'query': 'LangSmith evaluation features'}\n",
            "\u001b[36mTool's response: \n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view key metrics like RPS, error rates and costs.\n",
            "\n",
            "Evals​\n",
            "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
            "\n",
            "Get started by creating your first evaluation.\n",
            "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
            "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
            "Easily collect human feedback on your data to improve your application.\n",
            "\n",
            "Prompt Engineering​\n",
            "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
            "\n",
            "LangSmith + LangCh...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,917 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {\"query\": \"LangSmith evaluation features\"}\n",
            "\u001b[36mTool's response: \n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view key metrics like RPS, error rates and costs.\n",
            "\n",
            "Evals​\n",
            "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
            "\n",
            "Get started by creating your first evaluation.\n",
            "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
            "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
            "Easily collect human feedback on your data to improve your application.\n",
            "\n",
            "Prompt Engineering​\n",
            "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
            "\n",
            "LangSmith + LangCh...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,942 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {'query': 'LangSmith prompt engineering'}\n",
            "\u001b[36mTool's response: \n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view key metrics like RPS, error rates and costs.\n",
            "\n",
            "Evals​\n",
            "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
            "\n",
            "Get started by creating your first evaluation.\n",
            "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
            "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
            "Easily collect human feedback on your data to improve your application.\n",
            "\n",
            "Prompt Engineering​\n",
            "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
            "\n",
            "Skip to main conte...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,942 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {\"query\": \"LangSmith prompt engineering\"}\n",
            "\u001b[36mTool's response: \n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view key metrics like RPS, error rates and costs.\n",
            "\n",
            "Evals​\n",
            "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
            "\n",
            "Get started by creating your first evaluation.\n",
            "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
            "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
            "Easily collect human feedback on your data to improve your application.\n",
            "\n",
            "Prompt Engineering​\n",
            "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
            "\n",
            "Skip to main conte...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,964 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {'query': 'LangSmith framework-specific'}\n",
            "\u001b[36mTool's response: \n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
            "\n",
            "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
            "\n",
            "Skip to main contentOur Building Ambient Agents with LangGra...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:35,964 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {\"query\": \"LangSmith framework-specific\"}\n",
            "\u001b[36mTool's response: \n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
            "\n",
            "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
            "\n",
            "Skip to main contentOur Building Ambient Agents with LangGra...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:36,094 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {'query': 'LangSmith LLM application observability'}\n",
            "\u001b[36mTool's response: \n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
            "\n",
            "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Acade...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:36,094 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {\"query\": \"LangSmith LLM application observability\"}\n",
            "\u001b[36mTool's response: \n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
            "\n",
            "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Acade...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:36,125 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {'query': 'LangSmith features'}\n",
            "\u001b[36mTool's response: \n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
            "\n",
            "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
            "\n",
            "Skip to main contentOur Building Ambient Agents with LangGra...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:36,125 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {\"query\": \"LangSmith features\"}\n",
            "\u001b[36mTool's response: \n",
            "LangSmith + LangChain OSSLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.If you are using either of these, you can enable LangSmith tracing with a single environment variable.\n",
            "For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\n",
            "Observability​\n",
            "Observability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\n",
            "This is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\n",
            "\n",
            "Get started with LangSmith | 🦜️🛠️ LangSmith\n",
            "\n",
            "Skip to main contentOur Building Ambient Agents with LangGra...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:36,452 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: How does LangSmith support prompt engineering?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: The webpage provides information about LangSmith's support for prompt engineering.\n",
            "\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:36,452 - aiq.agent.react_agent.agent - INFO - [AGENT] Retrying ReAct Agent, including output parsing Observation\n",
            "2025-07-31 12:26:36,964 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: Is LangSmith framework-specific or can it be used with any LLM application?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: I now know the final answer\n",
            "Final Answer: LangSmith is framework-agnostic, meaning it can be used with or without LangChain's open source frameworks langchain and langgraph, and can be used with any LLM application.\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:36,968 - aiq.utils.type_converter - WARNING - Indirect type conversion used to convert <class 'str'> to <class 'str'>, which may lead to unintended conversions. Consider adding a direct converter from <class 'str'> to <class 'str'> to ensure correctness.\n",
            "Running workflow:  20%|█████▍                     | 1/5 [00:02<00:09,  2.28s/it]2025-07-31 12:26:37,206 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: What is the purpose of LangSmith's evaluation features?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: I have found information about LangSmith's evaluation features.\n",
            "\n",
            "Final Answer: The purpose of LangSmith's evaluation features is to enable users to assess the performance of their AI applications using high-quality evaluation datasets and metrics. The LangSmith SDK and UI make it easy to build and run evaluations, analyze results, and collect human feedback to improve the application.\u001b[39m\n",
            "------------------------------\n",
            "Running workflow:  40%|██████████▊                | 2/5 [00:02<00:03,  1.06s/it]2025-07-31 12:26:37,216 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: How does LangSmith support prompt engineering?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: The webpage provides information about LangSmith's support for prompt engineering.\n",
            "\n",
            "Action: None\n",
            "Action Input: None\n",
            "\n",
            "\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:37,218 - aiq.agent.react_agent.agent - WARNING - [AGENT] ReAct Agent wants to call tool None. In the ReAct Agent's configuration within the config file,there is no tool with that name: ['webpage_query', 'current_datetime']\n",
            "2025-07-31 12:26:37,961 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: How does LangSmith help with LLM application observability?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: I now know the final answer\n",
            "\n",
            "Final Answer: LangSmith helps with LLM application observability by providing LLM-native observability features that allow developers to get meaningful insights from their application throughout all stages of development, from prototyping to production. It enables tracing, analysis of traces, configuration of metrics, dashboards, and alerts, as well as evaluation of application performance and collection of human feedback on data. Additionally, LangSmith provides tools for prompt engineering, including automatic version control and collaboration features, to help developers find the perfect prompt for their application.\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:37,966 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: How does LangSmith support prompt engineering?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: I have found the information about LangSmith's support for prompt engineering.\n",
            "\n",
            "Action: webpage_query\n",
            "Action Input: {\"query\": \"LangSmith prompt engineering tools\"}\u001b[39m\n",
            "------------------------------\n",
            "Running workflow:  60%|████████████████▏          | 3/5 [00:03<00:01,  1.08it/s]2025-07-31 12:26:38,331 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: What are the main features of LangSmith?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: I now know the main features of LangSmith.\n",
            "\n",
            "Final Answer: The main features of LangSmith include:\n",
            "\n",
            "1. Observability: LangSmith provides LLM-native observability, allowing users to get meaningful insights from their application throughout all stages of development.\n",
            "2. Evaluation: LangSmith allows users to evaluate their application over production traffic, score application performance, and get human feedback on their data.\n",
            "3. Prompt Engineering: LangSmith provides tools for prompt engineering, enabling users to find the perfect prompt for their application, with features like automatic version control and collaboration.\n",
            "\n",
            "These features enable users to closely monitor and evaluate their LLM applications, ship quickly and with confidence, and improve the quality and development speed of their AI applications.\u001b[39m\n",
            "------------------------------\n",
            "Running workflow:  80%|█████████████████████▌     | 4/5 [00:03<00:00,  1.41it/s]2025-07-31 12:26:38,361 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {'query': 'LangSmith prompt engineering tools'}\n",
            "\u001b[36mTool's response: \n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view key metrics like RPS, error rates and costs.\n",
            "\n",
            "Evals​\n",
            "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
            "\n",
            "Get started by creating your first evaluation.\n",
            "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
            "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
            "Easily collect human feedback on your data to improve your application.\n",
            "\n",
            "Prompt Engineering​\n",
            "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
            "\n",
            "Skip to main conte...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:38,361 - aiq.agent.base - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[37mCalling tools: webpage_query\n",
            "\u001b[33mTool's input: {\"query\": \"LangSmith prompt engineering tools\"}\n",
            "\u001b[36mTool's response: \n",
            "Get started by adding tracing to your application.\n",
            "Create dashboards to view key metrics like RPS, error rates and costs.\n",
            "\n",
            "Evals​\n",
            "The quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\n",
            "\n",
            "Get started by creating your first evaluation.\n",
            "Quickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\n",
            "Analyze results of evaluations in the LangSmith UI and compare results over time.\n",
            "Easily collect human feedback on your data to improve your application.\n",
            "\n",
            "Prompt Engineering​\n",
            "While traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\n",
            "\n",
            "Skip to main conte...(rest of response truncated)\u001b[39m\n",
            "------------------------------\n",
            "2025-07-31 12:26:39,627 - aiq.agent.react_agent.agent - INFO - \n",
            "------------------------------\n",
            "[AGENT]\n",
            "\u001b[33mAgent input: How does LangSmith support prompt engineering?\n",
            "\u001b[36mAgent's thoughts: \n",
            "Thought: I now know the final answer\n",
            "\n",
            "Final Answer: LangSmith supports prompt engineering by providing a set of tools designed to enable and facilitate prompt engineering, including the ability to iterate on prompts with automatic version control and collaboration features, create and manage prompts programmatically in your application, and use the Playground to iterate on models and prompts.\u001b[39m\n",
            "------------------------------\n",
            "Running workflow: 100%|███████████████████████████| 5/5 [00:04<00:00,  1.01it/s]\n",
            "Evaluating Ragas nv_accuracy:   0%|                       | 0/5 [00:00<?, ?it/s]\n",
            "Evaluating Ragas nv_response_groundedness:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "Evaluating Ragas nv_context_relevance:   0%|              | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Evaluating Trajectory:   0%|                              | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "Evaluating Ragas nv_response_groundedness:  20%|▍ | 1/5 [00:00<00:03,  1.06it/s]\u001b[A2025-07-31 12:26:41,448 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,450 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,477 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,750 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,790 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,822 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,831 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,838 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,842 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,864 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,891 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,920 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,954 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:41,969 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,085 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,164 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,175 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,182 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,197 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,231 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,256 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,309 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,309 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,372 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,841 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "Evaluating Ragas nv_accuracy:  20%|███            | 1/5 [00:03<00:12,  3.23s/it]2025-07-31 12:26:42,898 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "2025-07-31 12:26:42,903 - aiq.utils.exception_handlers.automatic_retries - INFO - Retrying on exception [429] Too Many Requests\n",
            "{'status': 429, 'title': 'Too Many Requests'} with matched message [429] too many requests\n",
            "{'status': 429, 'title': 'too many requests'}\n",
            "Evaluating Ragas nv_accuracy:  40%|██████         | 2/5 [00:03<00:04,  1.39s/it]\n",
            "\n",
            "Evaluating Ragas nv_context_relevance:  20%|█▏    | 1/5 [00:02<00:08,  2.18s/it]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating Ragas nv_context_relevance: 100%|██████| 5/5 [00:05<00:00,  1.03s/it]\u001b[A\u001b[A\n",
            "Evaluating Ragas nv_response_groundedness: 100%|██| 5/5 [00:05<00:00,  1.20s/it]\n",
            "Evaluating Ragas nv_accuracy: 100%|███████████████| 5/5 [00:07<00:00,  1.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "Evaluating Trajectory:  20%|████▍                 | 1/5 [00:06<00:26,  6.57s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Evaluating Trajectory:  40%|████████▊             | 2/5 [00:06<00:08,  2.77s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Evaluating Trajectory:  60%|█████████████▏        | 3/5 [00:06<00:03,  1.59s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Evaluating Trajectory:  80%|█████████████████▌    | 4/5 [00:07<00:01,  1.16s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Evaluating Trajectory: 100%|██████████████████████| 5/5 [00:07<00:00,  1.50s/it]\u001b[A\u001b[A\u001b[A\n",
            "2025-07-31 12:26:49,031 - aiq.profiler.profile_runner - INFO - Wrote combined data to: .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/all_requests_profiler_traces.json\n",
            "2025-07-31 12:26:49,099 - aiq.profiler.profile_runner - INFO - Wrote merged standardized DataFrame to .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/standardized_data_all.csv\n",
            "2025-07-31 12:26:49,301 - aiq.profiler.profile_runner - INFO - Wrote inference optimization results to: .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/inference_optimization.json\n",
            "2025-07-31 12:26:51,242 - aiq.profiler.profile_runner - INFO - Nested stack analysis complete\n",
            "2025-07-31 12:26:51,260 - aiq.profiler.profile_runner - INFO - Concurrency spike analysis complete\n",
            "2025-07-31 12:26:51,261 - aiq.profiler.profile_runner - INFO - Wrote workflow profiling report to: .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/workflow_profiling_report.txt\n",
            "2025-07-31 12:26:51,262 - aiq.profiler.profile_runner - INFO - Wrote workflow profiling metrics to: .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/workflow_profiling_metrics.json\n",
            "2025-07-31 12:26:51,265 - aiq.eval.evaluate - INFO - Workflow output written to .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/workflow_output.json\n",
            "2025-07-31 12:26:51,266 - aiq.eval.evaluate - INFO - Evaluation results written to .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/rag_relevance_output.json\n",
            "2025-07-31 12:26:51,266 - aiq.eval.evaluate - INFO - Evaluation results written to .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/rag_groundedness_output.json\n",
            "2025-07-31 12:26:51,267 - aiq.eval.evaluate - INFO - Evaluation results written to .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/rag_accuracy_output.json\n",
            "2025-07-31 12:26:51,267 - aiq.eval.evaluate - INFO - Evaluation results written to .tmp/aiq/examples/evaluation_and_profiling/simple_web_query_eval/eval/trajectory_accuracy_output.json\n",
            "2025-07-31 12:26:51,267 - aiq.eval.utils.output_uploader - INFO - No S3 config provided; skipping upload.\n",
            "\u001b[0m\u001b[0m"
          ]
        }
      ],
      "source": [
        "!aiq eval --config_file examples/evaluation_and_profiling/simple_web_query_eval/configs/eval_config.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb560acb"
      },
      "outputs": [],
      "source": []
    }
  ]
}